{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio Naive Bayes: Spam or ham\n",
    "\n",
    "Vamos a crear nuestro propio filtro de *spam* a partir de los mensajes SMS que contiene el zip *smsspamcollection*.\n",
    "\n",
    "Para esta práctica vamos a usar el clasificador *Naive Bayes* como ya sabeis es un clasificador probabilístico. Antes de empezar debeis leer el fichero *readme* que se proporciona con la base de datos.\n",
    "\n",
    "En base a la idea que sugirió un compañero, he calculado distintas características en base a la longitud de los mensajes o de las palabras que lo forman. No he conseguido buenos resultados pero puede ser interesante ver el proceso de cálculo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observaciones: 5572\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                        sms_message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset from - https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection\n",
    "df = pd.read_table('data/SMSSpamCollection',\n",
    "                   sep='\\t',\n",
    "                   header=None,\n",
    "                   names=['label', 'sms_message'])\n",
    "\n",
    "print(\"Observaciones: \" + str(df.shape[0]))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balanceamos el conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham     747\n",
      "spam    747\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "balanceo = True\n",
    "if balanceo:\n",
    "    # Separamos las dos clases\n",
    "    df_majority = df[df.label==\"ham\"]\n",
    "    df_minority = df[df.label==\"spam\"]\n",
    "\n",
    "    df_majority_downsampled = resample(df_majority, \n",
    "                                     replace=False,    # sample without replacement\n",
    "                                     n_samples=747,     # to match minority class\n",
    "                                     random_state=33) \n",
    "\n",
    "    # Combinamos\n",
    "    df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    "\n",
    "    # Mostramos el nuevo dataset\n",
    "    print(df_downsampled.label.value_counts())\n",
    "    df = df_downsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos los tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vector = CountVectorizer(stop_words=\"english\",token_pattern=r'\\b[^_\\d\\W]+\\b', min_df=0.001, strip_accents='unicode') #set the variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculamos 2 características diferentes: \n",
    "* La longitud de los mensajes una vez hemos *tokenizado*.\n",
    "* La longitud media de las palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función para tokenizar\n",
    "funct = count_vector.build_tokenizer()\n",
    "\n",
    "# Función para el cálculo\n",
    "def averageLen(lst):\n",
    "    lengths = [len(i) for i in lst]\n",
    "    return 0 if len(lengths) == 0 else (float(sum(lengths)) / len(lengths)) \n",
    "\n",
    "# Creamos nuevas columnas en el dataframe en basa a la aplicación de las funciones anteriores\n",
    "df[\"sms_tokens\"] = df.sms_message.apply(funct)\n",
    "df[\"sms_length\"] = df.sms_tokens.apply(len) # la función len es de la base de python.\n",
    "df[\"mean_word\"] = df[\"sms_tokens\"].apply(averageLen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms_message</th>\n",
       "      <th>sms_tokens</th>\n",
       "      <th>sms_length</th>\n",
       "      <th>mean_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2598</td>\n",
       "      <td>ham</td>\n",
       "      <td>Got fujitsu, ibm, hp, toshiba... Got a lot of ...</td>\n",
       "      <td>[Got, fujitsu, ibm, hp, toshiba, Got, a, lot, ...</td>\n",
       "      <td>13</td>\n",
       "      <td>3.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3199</td>\n",
       "      <td>ham</td>\n",
       "      <td>7 lor... Change 2 suntec... Wat time u coming?</td>\n",
       "      <td>[lor, Change, suntec, Wat, time, u, coming]</td>\n",
       "      <td>7</td>\n",
       "      <td>4.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4605</td>\n",
       "      <td>ham</td>\n",
       "      <td>THANX 4 PUTTIN DA FONE DOWN ON ME!!</td>\n",
       "      <td>[THANX, PUTTIN, DA, FONE, DOWN, ON, ME]</td>\n",
       "      <td>7</td>\n",
       "      <td>3.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>954</td>\n",
       "      <td>ham</td>\n",
       "      <td>Also remember to get dobby's bowl from your car</td>\n",
       "      <td>[Also, remember, to, get, dobby, s, bowl, from...</td>\n",
       "      <td>10</td>\n",
       "      <td>3.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1402</td>\n",
       "      <td>ham</td>\n",
       "      <td>Kaiez... Enjoy ur tuition... Gee... Thk e seco...</td>\n",
       "      <td>[Kaiez, Enjoy, ur, tuition, Gee, Thk, e, secon...</td>\n",
       "      <td>19</td>\n",
       "      <td>3.473684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5537</td>\n",
       "      <td>spam</td>\n",
       "      <td>Want explicit SEX in 30 secs? Ring 02073162414...</td>\n",
       "      <td>[Want, explicit, SEX, in, secs, Ring, now, Cos...</td>\n",
       "      <td>11</td>\n",
       "      <td>4.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5540</td>\n",
       "      <td>spam</td>\n",
       "      <td>ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...</td>\n",
       "      <td>[ASKED, IF, CHATLINES, INCLU, IN, FREE, MINS, ...</td>\n",
       "      <td>26</td>\n",
       "      <td>3.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5547</td>\n",
       "      <td>spam</td>\n",
       "      <td>Had your contract mobile 11 Mnths? Latest Moto...</td>\n",
       "      <td>[Had, your, contract, mobile, Mnths, Latest, M...</td>\n",
       "      <td>26</td>\n",
       "      <td>4.730769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5566</td>\n",
       "      <td>spam</td>\n",
       "      <td>REMINDER FROM O2: To get 2.50 pounds free call...</td>\n",
       "      <td>[REMINDER, FROM, To, get, pounds, free, call, ...</td>\n",
       "      <td>25</td>\n",
       "      <td>4.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5567</td>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>[This, is, the, time, we, have, tried, contact...</td>\n",
       "      <td>25</td>\n",
       "      <td>3.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1494 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                        sms_message  \\\n",
       "2598   ham  Got fujitsu, ibm, hp, toshiba... Got a lot of ...   \n",
       "3199   ham     7 lor... Change 2 suntec... Wat time u coming?   \n",
       "4605   ham                THANX 4 PUTTIN DA FONE DOWN ON ME!!   \n",
       "954    ham    Also remember to get dobby's bowl from your car   \n",
       "1402   ham  Kaiez... Enjoy ur tuition... Gee... Thk e seco...   \n",
       "...    ...                                                ...   \n",
       "5537  spam  Want explicit SEX in 30 secs? Ring 02073162414...   \n",
       "5540  spam  ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...   \n",
       "5547  spam  Had your contract mobile 11 Mnths? Latest Moto...   \n",
       "5566  spam  REMINDER FROM O2: To get 2.50 pounds free call...   \n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...   \n",
       "\n",
       "                                             sms_tokens  sms_length  mean_word  \n",
       "2598  [Got, fujitsu, ibm, hp, toshiba, Got, a, lot, ...          13   3.384615  \n",
       "3199        [lor, Change, suntec, Wat, time, u, coming]           7   4.142857  \n",
       "4605            [THANX, PUTTIN, DA, FONE, DOWN, ON, ME]           7   3.571429  \n",
       "954   [Also, remember, to, get, dobby, s, bowl, from...          10   3.800000  \n",
       "1402  [Kaiez, Enjoy, ur, tuition, Gee, Thk, e, secon...          19   3.473684  \n",
       "...                                                 ...         ...        ...  \n",
       "5537  [Want, explicit, SEX, in, secs, Ring, now, Cos...          11   4.090909  \n",
       "5540  [ASKED, IF, CHATLINES, INCLU, IN, FREE, MINS, ...          26   3.692308  \n",
       "5547  [Had, your, contract, mobile, Mnths, Latest, M...          26   4.730769  \n",
       "5566  [REMINDER, FROM, To, get, pounds, free, call, ...          25   4.440000  \n",
       "5567  [This, is, the, time, we, have, tried, contact...          25   3.800000  \n",
       "\n",
       "[1494 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df # observamos el dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si nos fijamos, ninguna de las características calculadas tiene valores muy diferentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">sms_length</th>\n",
       "      <th colspan=\"8\" halign=\"left\">mean_word</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>ham</td>\n",
       "      <td>747.0</td>\n",
       "      <td>14.323963</td>\n",
       "      <td>10.727030</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>747.0</td>\n",
       "      <td>3.676963</td>\n",
       "      <td>0.690065</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.272727</td>\n",
       "      <td>3.625</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>spam</td>\n",
       "      <td>747.0</td>\n",
       "      <td>21.176707</td>\n",
       "      <td>5.507815</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>747.0</td>\n",
       "      <td>4.253469</td>\n",
       "      <td>0.668874</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.809524</td>\n",
       "      <td>4.200</td>\n",
       "      <td>4.658333</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sms_length                                                      \\\n",
       "           count       mean        std  min   25%   50%   75%    max   \n",
       "label                                                                  \n",
       "ham        747.0  14.323963  10.727030  1.0   7.0  11.0  19.0  117.0   \n",
       "spam       747.0  21.176707   5.507815  0.0  18.0  22.0  25.0   33.0   \n",
       "\n",
       "      mean_word                                                                 \n",
       "          count      mean       std  min       25%    50%       75%        max  \n",
       "label                                                                           \n",
       "ham       747.0  3.676963  0.690065  1.0  3.272727  3.625  4.000000   7.333333  \n",
       "spam      747.0  4.253469  0.668874  0.0  3.809524  4.200  4.658333  12.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"label\").describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí creamos los conjuntos de entrenamiento y de test en base a una de las categorias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our original set contains 1494 observations\n",
      "Our training set contains 1120 observations\n",
      "Our testing set contains 374 observations\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['mean_word'],\n",
    "                                                    df['label'],\n",
    "                                                    random_state=1)\n",
    "\n",
    "print(\"Our original set contains\", df.shape[0], \"observations\")\n",
    "print(\"Our training set contains\", X_train.shape[0], \"observations\")\n",
    "print(\"Our testing set contains\", X_test.shape[0], \"observations\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este gráfico nos permite ver como se distribuye la característica seleccionada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "spam = X_train[y_train == \"spam\"]\n",
    "ham = X_train[y_train == \"ham\"]\n",
    "\n",
    "plt.plot(spam, [0]*spam.shape[0], 'ro');\n",
    "plt.plot(ham, [1]*ham.shape[0], 'bx');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparamos los datos para el clasificador\n",
    "X_train = np.asarray(X_train).reshape(-1, 1)\n",
    "X_test = np.asarray(X_test).reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido a la sencillez del problema lo clasificaremos usando una regresión logística."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabri\\Anaconda3\\envs\\MADM2019\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic = LogisticRegression(C=1.0) #call the method\n",
    "logistic.fit(X_train, y_train) #train the classifier on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = logistic.predict(X_test) #predict using the model on the testing set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mostrar las metricas resumen de nuestro clasificador\n",
    "\n",
    "Vamos a usar la función ```classification_report ```\n",
    "\n",
    "[Documentación](https://scikit-learn.org/stable/modules/classes.html#classification-metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.67      0.71      0.69       187\n",
      "        spam       0.69      0.65      0.67       187\n",
      "\n",
      "    accuracy                           0.68       374\n",
      "   macro avg       0.68      0.68      0.68       374\n",
      "weighted avg       0.68      0.68      0.68       374\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De los resultados obtenidos podemos observar como de la creatividad para analizar el conjunto de datos pueden salir ideas que nos lleven a clasificarlos de maneras muy sencillas. \n",
    "\n",
    "De todas maneras, si comparamos los resultados obtenidos numericamente, hay que destacar que la aproximación del problema de la forma clásica nos proporciona mejores valores.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
